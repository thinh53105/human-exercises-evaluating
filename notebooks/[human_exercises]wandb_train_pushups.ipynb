{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d3HN0UzTFqBO"
      },
      "source": [
        "## Import Library"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pHLgBtt6FYxS"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.utils import Sequence, to_categorical\n",
        "from tensorflow import keras\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import cv2\n",
        "import glob, glob2\n",
        "import albumentations as A\n",
        "import time\n",
        "import random\n",
        "import os\n",
        "from sklearn.model_selection import train_test_split\n",
        "import shutil"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v900H8gPFxPK"
      },
      "outputs": [],
      "source": [
        "tf.config.list_physical_devices('GPU')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iVIyXgzxpn2j"
      },
      "outputs": [],
      "source": [
        "!pip install wandb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b_a7r1w9In3K"
      },
      "outputs": [],
      "source": [
        "import wandb \n",
        "from wandb.keras import WandbCallback\n",
        "\n",
        "!wandb login"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gLxsnKTGF8sw"
      },
      "source": [
        "## Prepare dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nztjL5cfF_sr"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dEnF2tWHvO1x"
      },
      "outputs": [],
      "source": [
        "%cd /content/drive/MyDrive/capstone-project/data/zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BzKbXgY1vdYZ"
      },
      "outputs": [],
      "source": [
        "!cp pushups.zip /content/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pHtpHrSuvj7R"
      },
      "outputs": [],
      "source": [
        "!unzip /content/pushups.zip -d /content/dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P6uzkTKdv_WC"
      },
      "outputs": [],
      "source": [
        "!rm /content/pushups.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RbL-z0fA2WMd"
      },
      "outputs": [],
      "source": [
        "# TYPE = 'up'\n",
        "TYPE = 'down'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f7sxN-CzkYZa"
      },
      "outputs": [],
      "source": [
        "class_names = ['right', 'wrong']\n",
        "num_classes = 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z6xOb70PkgAP"
      },
      "outputs": [],
      "source": [
        "dataset_folder = '/content/dataset/pushups/horizontal'\n",
        "save_path = '/content/drive/MyDrive/capstone-project/models/wandb_pushups'\n",
        "img_size = (224, 224)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TToaY3IWjZHp"
      },
      "outputs": [],
      "source": [
        "all_files = glob.glob(f'{dataset_folder}/*/{TYPE}/*/*[.png|.jpg]')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A7itgKKulA9S"
      },
      "outputs": [],
      "source": [
        "len(all_files)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eQ8h3yfgjiXt"
      },
      "outputs": [],
      "source": [
        "for cls_name in class_names:\n",
        "  print(cls_name, len(glob.glob(f'{dataset_folder}/*/{TYPE}/{cls_name}/*[.png|.jpg]')))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z5wabSovmCko"
      },
      "outputs": [],
      "source": [
        "for file_name in all_files:\n",
        "  if 'Copy' in file_name:\n",
        "    org = file_name.replace(' - Copy', '')\n",
        "    if org in all_files:\n",
        "      print(org)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_KWJWeTAwyJ_"
      },
      "source": [
        "## Augmentation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oc6abTQYwpeP"
      },
      "outputs": [],
      "source": [
        "transform = A.Compose([\n",
        "    \n",
        "        A.HorizontalFlip(p=0.5),\n",
        "        # A.VerticalFlip(p=0.5),\n",
        "        \n",
        "        A.ShiftScaleRotate(shift_limit=0.02, scale_limit=0.2, rotate_limit=5, p=0.5),\n",
        "        A.RandomBrightnessContrast(brightness_limit=0.25, contrast_limit=0.25, p=0.5),\n",
        "        A.RandomSunFlare(flare_roi=(0, 0, 1, 1), src_radius=50, p=0.1),\n",
        "        A.IAAPerspective(scale=(0.01, 0.01), p=0.1),\n",
        "        A.OneOf([\n",
        "            A.IAAAdditiveGaussianNoise(),\n",
        "            A.GaussNoise(),\n",
        "            A.Blur(blur_limit=3, p=0.3),\n",
        "            A.MedianBlur(blur_limit=3, p=0.3),\n",
        "        ], p=0.3),\n",
        "        A.CLAHE(clip_limit=1.5, p=0.3),\n",
        "        \n",
        "        A.RandomCrop(width=1020, height=764, p=0.5),\n",
        "    ])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "cvvR6-FKw16Q"
      },
      "outputs": [],
      "source": [
        "fig = plt.figure(figsize=(20, 20))\n",
        "columns = 4\n",
        "rows = 4\n",
        "for i in range(1, columns*rows +1):\n",
        "    test_img_path = random.choice(all_files)\n",
        "    img = cv2.imread(test_img_path)\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "    # img = cv2.resize(img, (256, 256), interpolation=cv2.INTER_AREA)\n",
        "    transformed = transform(image=img)\n",
        "    img = transformed[\"image\"]\n",
        "    # img = (( X[i-1].copy() + 1)*127.5).astype('uint8')\n",
        "    img = cv2.resize(img, (224, 224), interpolation=cv2.INTER_AREA)\n",
        "    fig.add_subplot(rows, columns, i)\n",
        "    plt.imshow(img)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cVZ0K0jcw9cO"
      },
      "source": [
        "## Data Loader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0m1GEa7kw8IS"
      },
      "outputs": [],
      "source": [
        "class DataGenerator(Sequence):\n",
        "    def __init__(self,\n",
        "                img_paths,\n",
        "                class_names,\n",
        "                batch_size=128,\n",
        "                img_size=(224,224),\n",
        "                n_channels=3,\n",
        "                shuffle=True,\n",
        "                augmentations=None,\n",
        "                ):\n",
        "        self.img_paths = img_paths\n",
        "        self.class_names = np.array(class_names) \n",
        "        self.batch_size = batch_size\n",
        "        self.img_size = img_size\n",
        "        self.n_channels = n_channels \n",
        "        self.n_classes = len(class_names)\n",
        "        self.shuffle = shuffle \n",
        "        self.augmentations = augmentations\n",
        "        self.on_epoch_end()\n",
        "        \n",
        "    def __len__(self):\n",
        "        'Denotes the number of batches per epoch'\n",
        "        return int(np.floor(len(self.img_paths) / self.batch_size))\n",
        "    \n",
        "    def __getitem__(self, index):\n",
        "        'Generate one batch of data'\n",
        "        # Generate indexes of the batch\n",
        "        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
        "        \n",
        "        # Find list of IDs\n",
        "        batch_img_paths = [self.img_paths[k] for k in indexes]\n",
        "        \n",
        "        # Generate data\n",
        "        X, y = self.__data_generation(batch_img_paths)\n",
        "        return X, y\n",
        "    \n",
        "    def on_epoch_end(self):\n",
        "        'Updates indexes after each epoch'\n",
        "        self.indexes = np.arange(len(self.img_paths))\n",
        "        if self.shuffle:\n",
        "            np.random.shuffle(self.indexes)\n",
        "    \n",
        "    def __data_generation(self, batch_img_paths):\n",
        "        X = np.empty((self.batch_size, *self.img_size, self.n_channels))\n",
        "        y = np.empty((self.batch_size, self.n_classes), dtype=int)\n",
        "        \n",
        "        try: \n",
        "            for i, img_path in enumerate(batch_img_paths):\n",
        "                img = cv2.imread(img_path)\n",
        "                img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "                # img = cv2.resize(img, (256, 256), interpolation=cv2.INTER_AREA)\n",
        "                # img = cv2.resize(img, self.img_size)\n",
        "                \n",
        "                if self.augmentations is not None:\n",
        "                    # Augment an image\n",
        "                    transformed = self.augmentations(image=img)\n",
        "                    img = transformed[\"image\"]\n",
        "                    \n",
        "                img = cv2.resize(img, self.img_size, interpolation=cv2.INTER_AREA)\n",
        "                label = img_path.split('/')[-2]\n",
        "                label = (self.class_names == label)*1\n",
        "\n",
        "                X[i] = img*1.0\n",
        "                y[i] = label\n",
        "        except:\n",
        "            print(img_path)\n",
        "        # Normalize batch data\n",
        "        X /= 127.5\n",
        "        X -= 1.\n",
        "\n",
        "        return X, y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "xT3Ao1cXw_8b"
      },
      "outputs": [],
      "source": [
        "# ## If not sure model works fine, should use val set\n",
        "X_train, X_test, _, _ = train_test_split(all_files, all_files, test_size=0.2, random_state=42)\n",
        "print(len(X_train))\n",
        "\n",
        "train_generator = DataGenerator(X_train, class_names, batch_size=32, augmentations=transform)\n",
        "test_generator = DataGenerator(X_test, class_names, batch_size=32, augmentations=transform)\n",
        "print(len(train_generator), len(test_generator))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "wV74aJKhlfdf"
      },
      "outputs": [],
      "source": [
        "# train_generator = DataGenerator(all_files, class_names, batch_size=32, augmentations=transform)\n",
        "# val_generator = DataGenerator(X_test, class_names)\n",
        "# print(train_generator.__len__())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "qTw_A_11ljIk"
      },
      "outputs": [],
      "source": [
        "### Check generator\n",
        "train_generator.on_epoch_end()\n",
        "X, y = train_generator.__getitem__(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "y7PRNKBwlmET"
      },
      "outputs": [],
      "source": [
        "fig = plt.figure(figsize=(20, 20))\n",
        "columns = 4\n",
        "rows = 4\n",
        "for i in range(1, columns*rows +1):\n",
        "    img = (( X[i-1].copy() + 1)*127.5).astype('uint8')\n",
        "    fig.add_subplot(rows, columns, i)\n",
        "    plt.imshow(img)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "I-4NVp-zzHwo"
      },
      "outputs": [],
      "source": [
        "%cd /content/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N4OxrBL0lygv"
      },
      "source": [
        "## Prepare Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "B0MfrDg2mlP0"
      },
      "outputs": [],
      "source": [
        "sweep_config = {\n",
        "    'method': 'grid', #grid, random\n",
        "    'metric': {\n",
        "      'name': 'val_accuracy',\n",
        "      'goal': 'maximize'   \n",
        "    },\n",
        "    'parameters': {\n",
        "        'type_data':{\n",
        "            'values': ['down']\n",
        "        },\n",
        "        'warmup_epochs':{\n",
        "            'values': [5]\n",
        "        },\n",
        "        'warmup_learning_rate':{\n",
        "            'values': [0.001]\n",
        "        },\n",
        "        'model_name': {  \n",
        "            'values': ['ResNet50', 'MobileNetV2', 'EfficientNetB0', 'VGG16', 'InceptionV3']\n",
        "        },\n",
        "        'finetune_epochs':{\n",
        "            'values': [10]\n",
        "        },\n",
        "        \"initial_learning_rate\":{\n",
        "            'values':[1e-4]\n",
        "        },\n",
        "        \"decay_steps\" : {\n",
        "            'values':[70]\n",
        "        },\n",
        "        \"decay_rate\" : {\n",
        "            'values':[0.93]\n",
        "        }\n",
        "    }\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "X9qdTAFYXnLR"
      },
      "outputs": [],
      "source": [
        "from wandb.keras import WandbCallback\n",
        "sweep_id = wandb.sweep(sweep_config, entity=\"xuannhamng28\",project=\"pushups-down\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "ruWoCQVnY91p"
      },
      "outputs": [],
      "source": [
        "def get_pretrained_model(model_name):\n",
        "    \n",
        "    if model_name == 'MobileNetV2':\n",
        "        base_model = tf.keras.applications.MobileNetV2(input_shape = (*img_size, 3), include_top = False, weights = \"imagenet\")\n",
        "    elif model_name == 'ResNet50':\n",
        "        base_model = tf.keras.applications.ResNet50(input_shape = (*img_size, 3), include_top = False, weights = \"imagenet\")\n",
        "    elif model_name == 'EfficientNetB0':\n",
        "        base_model = tf.keras.applications.efficientnet.EfficientNetB0(input_shape = (*img_size, 3), include_top = False, weights = \"imagenet\")\n",
        "    elif model_name == 'VGG16':\n",
        "        base_model = tf.keras.applications.vgg16.VGG16(input_shape = (*img_size, 3), include_top = False, weights = \"imagenet\")\n",
        "    elif model_name == 'InceptionV3':\n",
        "        base_model = tf.keras.applications.inception_v3.InceptionV3(input_shape = (*img_size, 3), include_top = False, weights = \"imagenet\")\n",
        "    else:\n",
        "        base_model = None\n",
        "    \n",
        "    return base_model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "E0OHItKytHiN"
      },
      "outputs": [],
      "source": [
        "METRICS =['accuracy',\n",
        "            keras.metrics.Precision(name=\"precision\"),\n",
        "            keras.metrics.Recall(name=\"recall\"),\n",
        "            keras.metrics.AUC(name=\"auc\"),]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "dITxx3r8Xgsh"
      },
      "outputs": [],
      "source": [
        "def warmup_model(model_name, epochs=5, learning_rate=0.001):\n",
        "\n",
        "    base_model = get_pretrained_model(model_name)\n",
        "\n",
        "    if base_model is None:\n",
        "        print(f'Model {model_name} not found!')\n",
        "        return None\n",
        "\n",
        "    base_model.trainable = False\n",
        "    x = base_model.output\n",
        "    x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
        "    x = tf.keras.layers.Dropout(0.2)(x)\n",
        "    x = tf.keras.layers.Dense(num_classes)(x)\n",
        "    outputs = tf.keras.layers.Activation('softmax')(x)\n",
        "\n",
        "    model =  tf.keras.Model(base_model.input, outputs)\n",
        "\n",
        "    early_callback = tf.keras.callbacks.EarlyStopping(monitor='accuracy', patience=2)\n",
        "    checkpoint_filepath = save_path + f'/tmp/warmup/{model_name}/checkpoint'\n",
        "\n",
        "    model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "        filepath=checkpoint_filepath,\n",
        "        save_weights_only=True,\n",
        "        monitor='val_accuracy', \n",
        "        mode='max',\n",
        "        save_best_only=True)\n",
        "    model.compile(\n",
        "      optimizer=keras.optimizers.Adam(learning_rate=learning_rate),\n",
        "      loss=keras.losses.CategoricalCrossentropy(),\n",
        "      metrics=METRICS\n",
        "    )\n",
        "\n",
        "    history = model.fit(train_generator, validation_data=test_generator, epochs=epochs, callbacks=[early_callback, model_checkpoint_callback, WandbCallback()])\n",
        "    # model.save(f'/content/drive/MyDrive/capstone-project/models/pushups-up/warmup_models/{model_name}_P')\n",
        "\n",
        "    return model,history,base_model "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "_qth6cGbqtB7"
      },
      "outputs": [],
      "source": [
        "def finetune():\n",
        "\n",
        "    config_defaults={\n",
        "        'warmup_epochs': 5,\n",
        "        'warmup_learning_rate':0.001,\n",
        "        'model_name': 'ResNet50',\n",
        "        'finetune_epochs':10,\n",
        "        \"initial_learning_rate\":1e-4,\n",
        "        \"decay_steps\" : 70,\n",
        "        \"decay_rate\" : 0.93,\n",
        "    }\n",
        "\n",
        "    wandb.init(config=config_defaults)\n",
        "    config = wandb.config\n",
        "    model_name = config.model_name\n",
        "    model, history, base_model = warmup_model(model_name,config.warmup_epochs,config.warmup_learning_rate)\n",
        "\n",
        "    base_model.trainable = True\n",
        "\n",
        "    lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
        "    initial_learning_rate=config.initial_learning_rate,\n",
        "    decay_steps = config.decay_steps,\n",
        "    decay_rate = config.decay_rate,\n",
        "    staircase=True)\n",
        "\n",
        "    model.compile(\n",
        "        optimizer=keras.optimizers.Adam(learning_rate=lr_schedule),\n",
        "        loss=keras.losses.CategoricalCrossentropy(),\n",
        "        metrics=METRICS\n",
        "    )\n",
        "    checkpoint_filepath = save_path + f'/tmp/finetune/{model_name}/checkpoint'\n",
        "\n",
        "    model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "        filepath=checkpoint_filepath,\n",
        "        save_weights_only=True,\n",
        "        monitor='val_accuracy', \n",
        "        mode='max',\n",
        "        save_best_only=True)\n",
        "    \n",
        "    total_epochs = config.finetune_epochs*config.warmup_epochs\n",
        "\n",
        "    history_fine = model.fit(train_generator, \\\n",
        "                             validation_data=test_generator, \\\n",
        "                             initial_epoch=history.epoch[-1],\\\n",
        "                             epochs=total_epochs, \\\n",
        "                             callbacks=[model_checkpoint_callback, WandbCallback()])\n",
        "    \n",
        "    model.save(f'/content/drive/MyDrive/capstone-project/models/pushups-down/finetune/{model_name}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "8Jkg2UCktkzS"
      },
      "outputs": [],
      "source": [
        "wandb.agent(sweep_id, finetune)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ldR2Si4WNqK0"
      },
      "source": [
        "# Test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K3Gfvuycz5Fr"
      },
      "outputs": [],
      "source": [
        "test_folder = \"/content/drive/MyDrive/capstone-project/data/test_dataset/pushups/horizontal\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2p_kwapsLDiT"
      },
      "outputs": [],
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import confusion_matrix"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_path = '/content/drive/MyDrive/capstone-project/models/pushups-up/finetune/MobileNetV2'"
      ],
      "metadata": {
        "id": "pEqIm8tW3soT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = keras.models.load_model(model_path)"
      ],
      "metadata": {
        "id": "Galta3_Y33kx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_img_list = glob.glob(f'{test_folder}/*/up/*/*[.jpg|.png]')"
      ],
      "metadata": {
        "id": "fygthx9g3-Vp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class_names = ['right', 'wrong']\n",
        "for path in test_img_list:\n",
        "    input = cv2.imread(path)[...,::-1]\n",
        "    input = cv2.resize(input,(224, 224), interpolation=cv2.INTER_AREA)\n",
        "    input = np.reshape(input,[1,224,224,3])*1.0\n",
        "    # input = keras.applications.mobilenet_v2.preprocess_input(input)\n",
        "    input /= 127.5\n",
        "    input -= 1.\n",
        "    out = model.predict(input)[0]\n",
        "    print(f'{path}--{class_names[np.argmax(out)]}')"
      ],
      "metadata": {
        "id": "3NJFQXVK4Hvc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2nPT1W3OzhlJ"
      },
      "outputs": [],
      "source": [
        "class_names = np.array(['right', 'wrong'])\n",
        "\n",
        "def generate_y_test(test_folder, ex_type, class_names):\n",
        "  test_img_list = glob.glob(f'{test_folder}/*/{ex_type}/*/*[.jpg|.png]')\n",
        "  test_labels = np.array([], dtype='int64')\n",
        "\n",
        "  for i in range(len(test_img_list)):\n",
        "    label_file = test_img_list[i].split('/')[-2]\n",
        "    label = (class_names == label_file)*1\n",
        "    # print(f'{label_file}: {label}')\n",
        "    test_labels = np.append(test_labels, np.argmax(label))\n",
        "  return test_labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cYFU6bZIugo3"
      },
      "outputs": [],
      "source": [
        "def test(model, img_list):\n",
        "    y_test_preds = np.array([], dtype='int64')\n",
        "\n",
        "    for path in img_list:\n",
        "      input = cv2.imread(path)[...,::-1]\n",
        "      input = cv2.resize(input,(224, 224), interpolation=cv2.INTER_AREA)\n",
        "      input = np.reshape(input,[1,224,224,3])*1.0\n",
        "      # input = keras.applications.mobilenet_v2.preprocess_input(input)\n",
        "      input /= 127.5\n",
        "      input -= 1.\n",
        "      out = model.predict(input)[0]\n",
        "      y_test_preds = np.append(y_test_preds,np.argmax(out))\n",
        "    return y_test_preds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cJy33SD0Oujp"
      },
      "outputs": [],
      "source": [
        "model_down_list = ['model-hardy-sweep-2:v5', 'model-bumbling-sweep-1:v9',\\\n",
        "                   'model-efficient-sweep-3:v11', 'model-lilac-sweep-2:v7',\\\n",
        "                   'model-soft-sweep-1:v7']\n",
        "model_up_list = ['model-copper-sweep-3:v5', 'model-playful-sweep-2:v11',\\\n",
        "                   'model-dauntless-sweep-1:v12', 'model-fluent-sweep-2:v6',\\\n",
        "                   'model-denim-sweep-1:v6']              "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PSlmG0E1r4GQ"
      },
      "outputs": [],
      "source": [
        "import wandb\n",
        "for ex_type in ['up', 'down']:\n",
        "  test_img_list = glob.glob(f'{test_folder}/*/{ex_type}/*/*[.jpg|.png]')\n",
        "  y_test = generate_y_test(test_folder=test_folder, ex_type=ex_type, class_names=class_names)\n",
        "  print(len(test_img_list))\n",
        "  print(len(y_test))\n",
        "  if ex_type == 'up':\n",
        "    model_list = model_up_list\n",
        "  else:\n",
        "    model_list = model_down_list\n",
        "  for model_name in model_list:\n",
        "    run = wandb.init()\n",
        "    artifact = run.use_artifact(f'xuannhamng28/pushups-{ex_type}/{model_name}', type='model')\n",
        "    artifact_dir = artifact.download()\n",
        "    model = keras.models.load_model(artifact_dir)\n",
        "    y_preds = test(model=model, img_list=test_img_list)\n",
        "    conf_matrix = confusion_matrix(y_test, y_preds)\n",
        "    sns.heatmap(conf_matrix, annot=True)\n",
        "    plt.savefig(f'/content/evaluate_result/{ex_type}/{model_name}_confusion_matrix.jpg')\n",
        "    plt.clf()\n",
        "    print(f'MODEL - {model} - EVALUATION RESULT: ')\n",
        "    print()\n",
        "    # accuracy: (tp + tn) / (p + n)\n",
        "    accuracy = accuracy_score(y_test, y_preds)\n",
        "    print('Accuracy: %f' % accuracy)\n",
        "    print()\n",
        "    # precision tp / (tp + fp)\n",
        "    precision = precision_score(y_test, y_preds)\n",
        "    print('Precision: %f' % precision)\n",
        "    print()\n",
        "    # recall: tp / (tp + fn)\n",
        "    recall = recall_score(y_test, y_preds)\n",
        "    print('Recall: %f' % recall)\n",
        "    print()\n",
        "    # f1: 2 tp / (2 tp + fp + fn)\n",
        "    f1 = f1_score(y_test, y_preds)\n",
        "    print('F1 score: %f' % f1)\n",
        "    print()\n",
        "    print('='*100)\n",
        "    f = open(f'/content/evaluate_result/{ex_type}/{model_name}_result.txt', \"a\")\n",
        "    f.write(f\"acc: {accuracy}\\n\")\n",
        "    f.write(f\"f1: {f1}\\n\")\n",
        "    f.write(f\"precision: {precision}\\n\")\n",
        "    f.write(f\"recall: {recall}\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HD0BIZXG31w_"
      },
      "outputs": [],
      "source": [
        "!zip -r /content/file.zip /content/evaluate_result"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "_KWJWeTAwyJ_"
      ],
      "provenance": []
    },
    "gpuClass": "premium",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}