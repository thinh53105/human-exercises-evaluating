{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d3HN0UzTFqBO"
      },
      "source": [
        "## Import Library"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pHLgBtt6FYxS"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.utils import Sequence, to_categorical\n",
        "from tensorflow import keras\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import cv2\n",
        "import glob, glob2\n",
        "import albumentations as A\n",
        "import time\n",
        "import random\n",
        "import os\n",
        "from sklearn.model_selection import train_test_split\n",
        "import shutil"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v900H8gPFxPK"
      },
      "outputs": [],
      "source": [
        "tf.config.list_physical_devices('GPU')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RXQ9hXe4Dz9n"
      },
      "outputs": [],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gLxsnKTGF8sw"
      },
      "source": [
        "## Prepare dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nztjL5cfF_sr"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dEnF2tWHvO1x"
      },
      "outputs": [],
      "source": [
        "%cd /content/drive/MyDrive/Shareddrives/thinh5/capstone-project/data/zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BzKbXgY1vdYZ"
      },
      "outputs": [],
      "source": [
        "!cp pushups.zip /content/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pHtpHrSuvj7R"
      },
      "outputs": [],
      "source": [
        "!unzip /content/pushups.zip -d /content/dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P6uzkTKdv_WC"
      },
      "outputs": [],
      "source": [
        "!rm /content/pushups.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RbL-z0fA2WMd"
      },
      "outputs": [],
      "source": [
        "TYPE = 'up'\n",
        "# TYPE = 'down'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f7sxN-CzkYZa"
      },
      "outputs": [],
      "source": [
        "class_names = ['right', 'wrong']\n",
        "num_classes = 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z6xOb70PkgAP"
      },
      "outputs": [],
      "source": [
        "dataset_folder = '/content/dataset/pushups/horizontal'\n",
        "save_path = '/content/drive/MyDrive/Shareddrives/thinh5/capstone-project/models/pushups'\n",
        "img_size = (224, 224)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TToaY3IWjZHp"
      },
      "outputs": [],
      "source": [
        "all_files = glob.glob(f'{dataset_folder}/*/{TYPE}/*/*[.png|.jpg]')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A7itgKKulA9S"
      },
      "outputs": [],
      "source": [
        "len(all_files)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eQ8h3yfgjiXt"
      },
      "outputs": [],
      "source": [
        "for cls_name in class_names:\n",
        "  print(cls_name, len(glob.glob(f'{dataset_folder}/*/{TYPE}/{cls_name}/*[.png|.jpg]')))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z5wabSovmCko"
      },
      "outputs": [],
      "source": [
        "for file_name in all_files:\n",
        "  if 'Copy' in file_name:\n",
        "    org = file_name.replace(' - Copy', '')\n",
        "    if org in all_files:\n",
        "      print(org)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_KWJWeTAwyJ_"
      },
      "source": [
        "## Augmentation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oc6abTQYwpeP"
      },
      "outputs": [],
      "source": [
        "transform = A.Compose([\n",
        "    \n",
        "        A.HorizontalFlip(p=0.5),\n",
        "        # A.VerticalFlip(p=0.5),\n",
        "        \n",
        "        A.ShiftScaleRotate(shift_limit=0.02, scale_limit=0.2, rotate_limit=5, p=0.5),\n",
        "        A.RandomBrightnessContrast(brightness_limit=0.25, contrast_limit=0.25, p=0.5),\n",
        "        A.RandomSunFlare(flare_roi=(0, 0, 1, 1), src_radius=50, p=0.1),\n",
        "        A.IAAPerspective(scale=(0.01, 0.01), p=0.1),\n",
        "        A.OneOf([\n",
        "            A.IAAAdditiveGaussianNoise(),\n",
        "            A.GaussNoise(),\n",
        "            A.Blur(blur_limit=3, p=0.3),\n",
        "            A.MedianBlur(blur_limit=3, p=0.3),\n",
        "        ], p=0.3),\n",
        "        A.CLAHE(clip_limit=1.5, p=0.3),\n",
        "        \n",
        "        A.RandomCrop(width=1020, height=764, p=0.5),\n",
        "    ])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cvvR6-FKw16Q"
      },
      "outputs": [],
      "source": [
        "fig = plt.figure(figsize=(20, 20))\n",
        "columns = 4\n",
        "rows = 4\n",
        "for i in range(1, columns*rows +1):\n",
        "    test_img_path = random.choice(all_files)\n",
        "    img = cv2.imread(test_img_path)\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "    # img = cv2.resize(img, (256, 256), interpolation=cv2.INTER_AREA)\n",
        "    transformed = transform(image=img)\n",
        "    img = transformed[\"image\"]\n",
        "    # img = (( X[i-1].copy() + 1)*127.5).astype('uint8')\n",
        "    img = cv2.resize(img, (224, 224), interpolation=cv2.INTER_AREA)\n",
        "    fig.add_subplot(rows, columns, i)\n",
        "    plt.imshow(img)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cVZ0K0jcw9cO"
      },
      "source": [
        "## Data Loader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0m1GEa7kw8IS"
      },
      "outputs": [],
      "source": [
        "class DataGenerator(Sequence):\n",
        "    def __init__(self,\n",
        "                img_paths,\n",
        "                class_names,\n",
        "                batch_size=128,\n",
        "                img_size=(224,224),\n",
        "                n_channels=3,\n",
        "                shuffle=True,\n",
        "                augmentations=None,\n",
        "                ):\n",
        "        self.img_paths = img_paths\n",
        "        self.class_names = np.array(class_names) \n",
        "        self.batch_size = batch_size\n",
        "        self.img_size = img_size\n",
        "        self.n_channels = n_channels \n",
        "        self.n_classes = len(class_names)\n",
        "        self.shuffle = shuffle \n",
        "        self.augmentations = augmentations\n",
        "        self.on_epoch_end()\n",
        "        \n",
        "    def __len__(self):\n",
        "        'Denotes the number of batches per epoch'\n",
        "        return int(np.floor(len(self.img_paths) / self.batch_size))\n",
        "    \n",
        "    def __getitem__(self, index):\n",
        "        'Generate one batch of data'\n",
        "        # Generate indexes of the batch\n",
        "        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
        "        \n",
        "        # Find list of IDs\n",
        "        batch_img_paths = [self.img_paths[k] for k in indexes]\n",
        "        \n",
        "        # Generate data\n",
        "        X, y = self.__data_generation(batch_img_paths)\n",
        "        return X, y\n",
        "    \n",
        "    def on_epoch_end(self):\n",
        "        'Updates indexes after each epoch'\n",
        "        self.indexes = np.arange(len(self.img_paths))\n",
        "        if self.shuffle:\n",
        "            np.random.shuffle(self.indexes)\n",
        "    \n",
        "    def __data_generation(self, batch_img_paths):\n",
        "        X = np.empty((self.batch_size, *self.img_size, self.n_channels))\n",
        "        y = np.empty((self.batch_size, self.n_classes), dtype=int)\n",
        "        \n",
        "        try: \n",
        "            for i, img_path in enumerate(batch_img_paths):\n",
        "                img = cv2.imread(img_path)\n",
        "                img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "                # img = cv2.resize(img, (256, 256), interpolation=cv2.INTER_AREA)\n",
        "                # img = cv2.resize(img, self.img_size)\n",
        "                \n",
        "                if self.augmentations is not None:\n",
        "                    # Augment an image\n",
        "                    transformed = self.augmentations(image=img)\n",
        "                    img = transformed[\"image\"]\n",
        "                    \n",
        "                img = cv2.resize(img, self.img_size, interpolation=cv2.INTER_AREA)\n",
        "                label = img_path.split('/')[-2]\n",
        "                label = (self.class_names == label)*1\n",
        "\n",
        "                X[i] = img*1.0\n",
        "                y[i] = label\n",
        "        except:\n",
        "            print(img_path)\n",
        "        # Normalize batch data\n",
        "        X /= 127.5\n",
        "        X -= 1.\n",
        "\n",
        "        return X, y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xT3Ao1cXw_8b"
      },
      "outputs": [],
      "source": [
        "# ## If not sure model works fine, should use val set\n",
        "X_train, X_test, _, _ = train_test_split(all_files, all_files, test_size=0.2, random_state=42)\n",
        "print(len(X_train))\n",
        "\n",
        "train_generator = DataGenerator(X_train, class_names, batch_size=32, augmentations=transform)\n",
        "test_generator = DataGenerator(X_test, class_names, batch_size=32, augmentations=transform)\n",
        "print(len(train_generator), len(test_generator))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wV74aJKhlfdf"
      },
      "outputs": [],
      "source": [
        "# train_generator = DataGenerator(all_files, class_names, batch_size=32, augmentations=transform)\n",
        "# val_generator = DataGenerator(X_test, class_names)\n",
        "# print(train_generator.__len__())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qTw_A_11ljIk"
      },
      "outputs": [],
      "source": [
        "### Check generator\n",
        "train_generator.on_epoch_end()\n",
        "X, y = train_generator.__getitem__(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y7PRNKBwlmET"
      },
      "outputs": [],
      "source": [
        "fig = plt.figure(figsize=(20, 20))\n",
        "columns = 4\n",
        "rows = 4\n",
        "for i in range(1, columns*rows +1):\n",
        "    img = (( X[i-1].copy() + 1)*127.5).astype('uint8')\n",
        "    fig.add_subplot(rows, columns, i)\n",
        "    plt.imshow(img)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N4OxrBL0lygv"
      },
      "source": [
        "## Prepare Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pz4RQnnJlpBx"
      },
      "outputs": [],
      "source": [
        "base_model = tf.keras.applications.MobileNetV2(input_shape = (*img_size, 3), include_top = False, weights = \"imagenet\")\n",
        "base_model.trainable = False\n",
        "\n",
        "x = base_model.output\n",
        "x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
        "x = tf.keras.layers.Dropout(0.2)(x)\n",
        "x = tf.keras.layers.Dense(num_classes)(x)\n",
        "outputs = tf.keras.layers.Activation('softmax')(x)\n",
        "model =  tf.keras.Model(base_model.input, outputs)\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8hV-FBCol3I8"
      },
      "outputs": [],
      "source": [
        "### Should use 'val_accuracy' if not sure that model works fine\n",
        "METRICS =['accuracy',\n",
        "            keras.metrics.Precision(name=\"precision\"),\n",
        "            keras.metrics.Recall(name=\"recall\"),\n",
        "            keras.metrics.AUC(name=\"auc\"),]\n",
        "early_callback = tf.keras.callbacks.EarlyStopping(monitor='accuracy', patience=2)\n",
        "\n",
        "checkpoint_filepath = save_path + '/tmp/checkpoint'\n",
        "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_filepath,\n",
        "    save_weights_only=True,\n",
        "    monitor='val_accuracy', \n",
        "    mode='max',\n",
        "    save_best_only=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fWsHB3h-mBSa"
      },
      "source": [
        "## Train"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gx4NQtL_mElU"
      },
      "source": [
        "### Warm up model with hight LR + free base model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5auCu9kdmAFg"
      },
      "outputs": [],
      "source": [
        "learning_rate = 0.001\n",
        "num_epochs = 5\n",
        "base_model.trainable = False\n",
        "model.compile(\n",
        "    optimizer=keras.optimizers.Adam(learning_rate=learning_rate),\n",
        "    loss=keras.losses.CategoricalCrossentropy(),\n",
        "    metrics=METRICS\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W-tYSJAimL7t"
      },
      "outputs": [],
      "source": [
        "# history = model.fit(train_generator, epochs=num_epochs, callbacks=[early_callback, model_checkpoint_callback])\n",
        "history = model.fit(train_generator, validation_data=test_generator, epochs=num_epochs, callbacks=[early_callback, model_checkpoint_callback])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zn6laVLTmxsk"
      },
      "source": [
        "### Fine tune model with low learning rate + unfreeze base model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R-0NDFusmNyl"
      },
      "outputs": [],
      "source": [
        "num_epochs = 40\n",
        "base_model.trainable = True\n",
        "# extractor.trainable = True\n",
        "\n",
        "initial_learning_rate = 1e-4\n",
        "lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
        "    initial_learning_rate,\n",
        "    decay_steps=70,\n",
        "    decay_rate=0.93,\n",
        "    staircase=True)\n",
        "# boundaries = [700]\n",
        "# values = [1e-6, 5e-7]\n",
        "# learning_rate_fn = keras.optimizers.schedules.PiecewiseConstantDecay(\n",
        "#     boundaries, values)\n",
        "model.compile(\n",
        "    optimizer=keras.optimizers.Adam(learning_rate=lr_schedule),\n",
        "    loss=keras.losses.CategoricalCrossentropy(),\n",
        "    metrics=METRICS\n",
        ")\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "alVEGA34m4to"
      },
      "outputs": [],
      "source": [
        "# history = model.fit(train_generator, epochs=num_epochs, callbacks=[early_callback, model_checkpoint_callback])\n",
        "history = model.fit(train_generator, validation_data=test_generator, epochs=num_epochs, callbacks=[model_checkpoint_callback])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E0XbPzvgm8lO"
      },
      "source": [
        "### Save trained model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aaKX237cm6w1"
      },
      "outputs": [],
      "source": [
        "from datetime import datetime\n",
        "\n",
        "# datetime object containing current date and time\n",
        "now = datetime.now()\n",
        " \n",
        "print(\"now =\", now)\n",
        "\n",
        "# dd/mm/YY H:M:S\n",
        "dt_string = now.strftime(\"%d%m%Y_%H%M%S\")\n",
        "print(\"date and time =\", dt_string)\n",
        "model_save_path = f'{save_path}/best_mobinet_{TYPE}_{dt_string}'\n",
        "\n",
        "model.save(model_save_path)\n",
        "print(f'Model saved at {model_save_path}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XZn06DqXnEGI"
      },
      "source": [
        "## Test Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XEjw3mTJ-DJg"
      },
      "outputs": [],
      "source": [
        "from google.colab.patches import cv2_imshow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5pStU8Nmm_-I"
      },
      "outputs": [],
      "source": [
        "model_save_path = \"/content/drive/MyDrive/Shareddrives/thinh5/capstone-project/models/pushups-down/finetune/MobileNetV2_0.001_0.0001\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pzKIxDOZ9Gjt"
      },
      "outputs": [],
      "source": [
        "### Put the path of saved model\n",
        "print (\"load model ....\")\n",
        "model = keras.models.load_model(model_save_path)\n",
        "print (\"load model successfully!\")\n",
        "img_size = 224"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j8Ro3RV56zzv"
      },
      "outputs": [],
      "source": [
        "# !pip install wandb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q9XSXtNF6yoj"
      },
      "outputs": [],
      "source": [
        "# import wandb\n",
        "# run = wandb.init()\n",
        "# artifact = run.use_artifact('xuannhamng28/squats3-up/mobilenet:v5', type='model')\n",
        "# artifact_dir = artifact.download()\n",
        "# model = keras.models.load_model(artifact_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-MRN2VA-9RjZ"
      },
      "outputs": [],
      "source": [
        "TYPE = 'down'\n",
        "img_size = 224\n",
        "class_names = ['right', 'wrong']\n",
        "num_classes = 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S63KwRogNSnb"
      },
      "outputs": [],
      "source": [
        "test_folder = \"/content/drive/MyDrive/Shareddrives/thinh5/capstone-project/data/test_dataset/pushups/horizontal\"\n",
        "test_img_list = glob.glob(f'{test_folder}/*/{TYPE}/*[right|wrong]/*[.jpg|.png]')\n",
        "len(test_img_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uGLMAFB1-GPj"
      },
      "outputs": [],
      "source": [
        "def classify(img_name, show=True):\n",
        "    \n",
        "    input = cv2.imread(img_name)[...,::-1]\n",
        "    input = cv2.resize(input,(img_size, img_size), interpolation=cv2.INTER_AREA)\n",
        "    input = np.reshape(input,[1,224,224,3])*1.0\n",
        "    # input = keras.applications.mobilenet_v2.preprocess_input(input)\n",
        "    input /= 127.5\n",
        "    input -= 1.\n",
        "    out = model.predict(input)[0]\n",
        "    print(out)\n",
        "    if show:\n",
        "      print(img_name)\n",
        "      cv2_imshow(cv2.imread(img_name))\n",
        "    return class_names[np.argmax(out)],np.round(out[np.argmax(out)],4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uoCO6_Nv994h"
      },
      "outputs": [],
      "source": [
        "classify(test_img_list[7])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GBZb_uIJ-mA0"
      },
      "outputs": [],
      "source": [
        "total, count = 0, 0\n",
        "for img_path in test_img_list:\n",
        "  print(img_path)\n",
        "  label = img_path.split('/')[-2]\n",
        "  pred_lb, pred_conf = classify(img_path, show=False)\n",
        "  if pred_lb != label:\n",
        "    count += 1\n",
        "    cv2_imshow(cv2.resize(cv2.imread(img_path), (img_size, img_size)))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zZa-_nKeFcEz"
      },
      "outputs": [],
      "source": [
        "total, count, len(test_img_list)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uG15YdlInNYm"
      },
      "source": [
        "##  Convert model to tflite"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nP_Mm62S7qDr"
      },
      "outputs": [],
      "source": [
        "saved_model_name = 'MobileNetV2_down'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZibdSfIanQEg"
      },
      "outputs": [],
      "source": [
        "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "tflite_model = converter.convert()\n",
        "\n",
        "\n",
        "# Save the model. \n",
        "tflite_save_path = f\"/content/drive/MyDrive/Shareddrives/thinh5/capstone-project/models/tflite/{saved_model_name}.tflite\"\n",
        "print(tflite_save_path)\n",
        "with open(tflite_save_path, 'wb') as f:\n",
        "  f.write(tflite_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aoWAo_UGsMN7"
      },
      "outputs": [],
      "source": [
        "interpreter = tf.lite.Interpreter(model_path=tflite_save_path)\n",
        "interpreter.allocate_tensors()\n",
        "\n",
        "# Get input and output tensors.\n",
        "input_details = interpreter.get_input_details()\n",
        "output_details = interpreter.get_output_details()\n",
        "\n",
        "# Test the model on random input data.\n",
        "input_shape = input_details[0]['shape']"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_img_path = test_img_list[7]\n",
        "test_img_path"
      ],
      "metadata": {
        "id": "T3Q5swNLdVNR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input = cv2.imread(test_img_path)\n",
        "input = cv2.resize(input, dsize=(224, 224), interpolation=cv2.INTER_AREA)\n",
        "input = cv2.cvtColor(input, cv2.COLOR_BGR2RGB)\n",
        "input = (input/127.5) - 1\n",
        "input = input.reshape(1, 224, 224, 3)"
      ],
      "metadata": {
        "id": "V8z0LgzOdb-O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-NwTp5KvsPKv"
      },
      "outputs": [],
      "source": [
        "input_data = tf.cast(input,tf.float32)\n",
        "interpreter.set_tensor(input_details[0]['index'], input_data)\n",
        "\n",
        "interpreter.invoke()\n",
        "\n",
        "# The function `get_tensor()` returns a copy of the tensor data.\n",
        "# Use `tensor()` in order to get a pointer to the tensor.\n",
        "output_data = interpreter.get_tensor(output_details[0]['index'])[0]\n",
        "print(output_data)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class_idx = tf.argmax(output_data, axis=0)\n",
        "class_idx"
      ],
      "metadata": {
        "id": "QWQ9XiZneZqh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UhLSoiOjfyuK"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "_KWJWeTAwyJ_",
        "cVZ0K0jcw9cO",
        "N4OxrBL0lygv",
        "fWsHB3h-mBSa",
        "Gx4NQtL_mElU",
        "Zn6laVLTmxsk",
        "E0XbPzvgm8lO"
      ],
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}